<!DOCTYPE html>
<html>
<head>
    <title>ZC' bolg for test</title>
    <meta charset="utf-8">

    <!-- 引入配置文件 -->
    
<link rel="stylesheet" href="/css/main.css">


    <!-- 字体图片库 -->
    
<link rel="stylesheet" href="/lib/font-awesome-4.7.0/css/font-awesome.min.css">


    <!-- 代码高亮库 -->
    
<link rel="stylesheet" href="/lib/highlight/styles/atom-one-dark.css">

    
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="YYHY's Blog" type="application/atom+xml">
</head>
<body>

    <div id="main">
        <!-- 引入侧边栏 -->
        <aside id="#aside">
            <!-- 搜索栏 -->
<div id="search">
    <input class="search-input" type="text" placeholder="search">
    <i id="search-icon" class="fa fa-bars" title="切换目录与索引">
</div>


<!-- 侧边目录栏 -->
<div id="tree">
    

    
                    <ul>
                        <li class="file">
                            <a href="/2023/07/03/Front-matter示例/">
                                <i class="fa fa-file"></i>
                                Front-matter示例
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file active">
                            <a href="/2023/07/20/SVM/">
                                <i class="fa fa-file"></i>
                                SVM
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2024/08/13/使用Unity创建一个类似MC的游戏场景（一）/">
                                <i class="fa fa-file"></i>
                                使用Unity创建一个类似MC的游戏场景（一）
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2023/07/22/决策树/">
                                <i class="fa fa-file"></i>
                                决策树
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2023/07/25/图像表示和图像增强（一）/">
                                <i class="fa fa-file"></i>
                                图像表示和图像增强（一）
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2023/07/29/图像表示和图像增强（二）/">
                                <i class="fa fa-file"></i>
                                图像表示和图像增强（二）
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2023/06/30/数据结构课程实习/">
                                <i class="fa fa-file"></i>
                                数据结构课程实习
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2023/07/16/线性回归/">
                                <i class="fa fa-file"></i>
                                线性回归
                            </a>
                        </li>
                    </ul>
    
                    <ul>
                        <li class="file">
                            <a href="/2023/07/18/逻辑回归/">
                                <i class="fa fa-file"></i>
                                逻辑回归
                            </a>
                        </li>
                    </ul>
    
</div>

<!-- 最尾部添加，这里就不列以前的代码了 -->
<div id="toc" style="display: none;"></div>

        </aside>

        <!-- 引入导航 -->
        <nav>
            <ul id="menu">
    <!-- 内部链接本页面直接跳转 -->
    
    <li class="menu-item">
        <a href="/ || fas fa-home" class="menu-item-link">首页</a>
    </li>
    
    <li class="menu-item">
        <a href="/archives/ || fas fa-archive" class="menu-item-link">归档</a>
    </li>
    
    <li class="menu-item">
        <a href="/tags/ || fas fa-tags" class="menu-item-link">标签</a>
    </li>
    
    <li class="menu-item">
        <a href="/categories/ || fas fa-folder-open" class="menu-item-link">分类</a>
    </li>
    
    <li class="menu-item">
        <a href="/about/ || fas fa-heart" class="menu-item-link">关于</a>
    </li>
    

    <!-- 外部链接打开新的窗口跳转 -->
    
    <li class="menu-item">
        <a href="https://www.cnblogs.com/yyhh/p/11058985.html" class="menu-item-link" target="_blank">参考教程</a>
    </li>
    
    <li class="menu-item">
        <a href="https://github.com/youyouhangyong" class="menu-item-link" target="_blank">github</a>
    </li>
    

</ul>

        </nav>

        <!-- 引入正文 -->
        <div id="content">
      <div>
    <span id="post-author">作者: YYHY</span>
    <span id="post-date">2023-07-20 12:37:32</span>
</div>

<div id="article">
    <p><strong>SVM(支持向量机)</strong>是一种常用的机器学习算法,<strong>主要用于分类问题</strong>,但是也可以扩展做回归任务。</p>
<p>SVM的主要思想是:</p>
<ol type="1">
<li>将样本<strong>映射</strong>到高维空间中,<strong>转换为线性可分问题</strong>。</li>
<li>在高维空间中,存在很多分隔超平面可以将不同类样本完全分开。SVM试图找到这些超平面的最优解,即最大间隔超平面,这样可以获得最佳的分类
GENERALIZATION（泛化）能力。</li>
<li>最大间隔超平面可以由支持向量决定,而支持向量就是离分隔超平面最近的样本点。</li>
<li>通过核函数,SVM可以隐式地实现高维映射,并建立优化问题求解最大间隔超平面,
thus分类模型。</li>
</ol>
<p>SVM决策超平面的推导过程:</p>
<p>设训练样本为<span class="math inline">\(\{(x_1, y_1), (x_2, y_2),
\cdots, (x_n, y_n)\}\)</span>,其中<span class="math inline">\(x_i \in
\mathbb{R}^d\)</span>,<span class="math inline">\(y_i \in
\{-1,+1\}\)</span>。</p>
<p>SVM的目标是找到一个分类超平面:</p>
<p><span class="math display">\[w^Tx + b = 0\]</span></p>
<p>将两类样本完全分开,且间隔尽可能大。</p>
<p>定义样本<span
class="math inline">\(x_i\)</span>到超平面的函数间隔为:</p>
<p><span class="math display">\[d_i = \frac{|w^Tx_i +
b|}{||w||}\]</span></p>
<p>则求最大间隔等价于最小化<span
class="math inline">\(||w||\)</span>,满足约束:</p>
<p><span class="math display">\[y_i(w^Tx_i + b) \geq 1,
i=1,2,\cdots,n\]</span></p>
<p>即解决以下优化问题:</p>
<p><span class="math display">\[\min\limits_{w,b}
\frac{1}{2}||w||^2\]</span></p>
<p><span class="math display">\[\text{s.t. } y_i(w^Tx_i + b) \geq 1,
i=1,2,\cdots,n\]</span></p>
<p>引入拉格朗日乘子<span class="math inline">\(\alpha_i \geq
0\)</span>,构建拉格朗日函数:</p>
<p><span class="math display">\[L(w,b,\alpha) = \frac{1}{2}||w||^2 -
\sum\limits_{i=1}^{n}{\alpha_i[y_i(w^Tx_i + b) - 1]}\]</span></p>
<p>对<span class="math inline">\(w,b\)</span>的偏导数等于0可得:</p>
<p><span class="math display">\[w = \sum\limits_{i=1}^{n}{\alpha_i y_i
x_i}\]</span></p>
<p><span class="math display">\[\sum\limits_{i=1}^{n}{\alpha_i y_i} =
0\]</span></p>
<p>将<span class="math inline">\(w\)</span>代回原问题,得到对偶问题:</p>
<p><span class="math display">\[\max\limits_{\alpha}
\sum\limits_{i=1}^{n}{\alpha_i} -
\frac{1}{2}\sum\limits_{i,j=1}^{n}{\alpha_i \alpha_j y_i y_j (x_i \cdot
x_j)}\]</span></p>
<p><span class="math display">\[\text{s.t. } \alpha_i \geq 0,
\sum\limits_{i=1}^{n}{\alpha_i y_i} = 0\]</span></p>
<p>求解得到<span
class="math inline">\(\alpha\)</span>,则最大间隔超平面为:</p>
<p><span class="math display">\[w = \sum\limits_{i=1}^{n}{\alpha_i y_i
x_i}\]</span> <span class="math display">\[b = \frac{1}{y_i} - w \cdot
x_i, \text{对任一支持向量}i\]</span></p>
<p>将输入样本映射到高维特征空间。SVM试图在高维空间中找到一个最优分类超平面,以获得最佳的分类效果。</p>
<p>通过核函数实现了从低维到高维的隐式映射。常见的核函数有线性核、多项式核、Gauss核(RBF核)等。</p>
<p>通过求解对偶问题,只需要输入数据的内积,而输入数据的高维映射可以通过核函数实现。</p>
<p>这样就可以在低维输入空间构建最优分隔超平面,而实际上是在高维特征空间实现,从而处理非线性分类问题。</p>
<p>常见的Gauss
RBF核将输入映射到无穷维,可以看成在高维空间构建一个泛化能力最强的分类模型。</p>
<p>核技巧扩展了SVM的适用范围,使其不仅适用于线性可分问题,也可用于复杂的非线性分类问题。</p>
<p>通过选择不同的核函数,可以灵活地处理各种类型的数据集。</p>
<p>核技巧是SVM强大的原因之一,它寻求高维映射以求分类的最优解,却只需要计算低维数据的内积,
thus有效实现了“维度灾难”的解决。</p>
<hr />
<p>以下是一个在二维求解决策平面的代码示例：</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成样本数据</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.r_[np.random.randn(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">-</span> [<span class="dv">2</span>, <span class="dv">2</span>], np.random.randn(<span class="dv">20</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="dv">2</span>, <span class="dv">2</span>]]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> <span class="dv">20</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">20</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 拟合SVM模型</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">&#39;linear&#39;</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>clf.fit(X, y)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制样本点</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">30</span>, cmap<span class="op">=</span>plt.cm.Paired)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制决策边界</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.gca()</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>xlim <span class="op">=</span> ax.get_xlim()</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>ylim <span class="op">=</span> ax.get_ylim()</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 创建网格采样点</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> np.linspace(xlim[<span class="dv">0</span>], xlim[<span class="dv">1</span>], <span class="dv">30</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>yy <span class="op">=</span> np.linspace(ylim[<span class="dv">0</span>], ylim[<span class="dv">1</span>], <span class="dv">30</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>YY, XX <span class="op">=</span> np.meshgrid(yy, xx)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>xy <span class="op">=</span> np.vstack([XX.ravel(), YY.ravel()]).T</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> clf.decision_function(xy).reshape(XX.shape)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制决策边界</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>ax.contour(XX, YY, Z, colors<span class="op">=</span><span class="st">&#39;k&#39;</span>, levels<span class="op">=</span>[<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, linestyles<span class="op">=</span>[<span class="st">&#39;--&#39;</span>, <span class="st">&#39;-&#39;</span>, <span class="st">&#39;--&#39;</span>])</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制支持向量</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>ax.scatter(clf.support_vectors_[:, <span class="dv">0</span>], clf.support_vectors_[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">100</span>, linewidth<span class="op">=</span><span class="dv">1</span>, facecolors<span class="op">=</span><span class="st">&#39;none&#39;</span>,</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>           edgecolors<span class="op">=</span><span class="st">&#39;k&#39;</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><a target="_blank" rel="noopener" href="https://imgse.com/i/pC7xzjJ"><img
src="https://s1.ax1x.com/2023/07/20/pC7xzjJ.png"
alt="pC7xzjJ.png" /></a></p>
<p>在这个例子中,我们先随机生成了两类二维样本数据,然后训练一个线性核SVM模型,并画出了决策边界。支持向量也被标记出来了。</p>
<hr />
<p>同样可以求解非线性问题：</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> svm</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成一个环形分布的数据集</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack((np.random.randn(<span class="dv">150</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>               np.random.randn(<span class="dv">150</span>, <span class="dv">2</span>) <span class="op">-</span> [<span class="dv">1</span>, <span class="dv">2</span>]))</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> <span class="dv">150</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">150</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用RBF核的SVM</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">&#39;rbf&#39;</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>clf.fit(X, y)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制样本点</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">30</span>, cmap<span class="op">=</span>plt.cm.Paired)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制决策边界</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.gca()</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>xlim <span class="op">=</span> ax.get_xlim()</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>ylim <span class="op">=</span> ax.get_ylim()</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 创建网格采样点</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>xx, yy <span class="op">=</span> np.meshgrid(np.linspace(xlim[<span class="dv">0</span>], xlim[<span class="dv">1</span>], <span class="dv">200</span>),</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>                     np.linspace(ylim[<span class="dv">0</span>], ylim[<span class="dv">1</span>], <span class="dv">200</span>))</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> clf.decision_function(np.c_[xx.ravel(), yy.ravel()])</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> Z.reshape(xx.shape)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>ax.contourf(xx, yy, Z, alpha<span class="op">=</span><span class="fl">0.75</span>, cmap<span class="op">=</span>plt.cm.Paired)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(xlim)</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(ylim)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><a target="_blank" rel="noopener" href="https://imgse.com/i/pC7z14f"><img
src="https://s1.ax1x.com/2023/07/20/pC7z14f.png"
alt="pC7z14f.png" /></a></p>
<p>通过构造一个环形分布的二维非线性数据,然后使用RBF核的SVM进行建模。可以看到SVM学会了一个非线性的决策边界将两类不同程度的区分开。</p>
<hr />
<p>生成了200个样本的二维数据集,然后进行了三维可视化。通过升维操作,SVM可以学习到一个线性的决策面对这些点进行分类。</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mpl_toolkits.mplot3d <span class="im">import</span> Axes3D</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 生成二维非线性可分数据集</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">100</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> np.random.randn(<span class="dv">100</span>, <span class="dv">2</span>) <span class="op">+</span> [<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> np.random.randn(<span class="dv">100</span>, <span class="dv">2</span>) <span class="op">-</span> [<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.vstack((X1, X2)).astype(np.float32)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.array([<span class="dv">0</span>] <span class="op">*</span> <span class="dv">100</span> <span class="op">+</span> [<span class="dv">1</span>] <span class="op">*</span> <span class="dv">100</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 升维到三维</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>X_3d <span class="op">=</span> np.hstack((X, (X[:, <span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> X[:, <span class="dv">1</span>]<span class="op">**</span><span class="dv">2</span>)[:, <span class="va">None</span>]))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 三维可视化</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure()</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> fig.add_subplot(<span class="dv">111</span>, projection<span class="op">=</span><span class="st">&#39;3d&#39;</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>ax.scatter(X_3d[:, <span class="dv">0</span>], X_3d[:, <span class="dv">1</span>], X_3d[:, <span class="dv">2</span>], c<span class="op">=</span>y, s<span class="op">=</span><span class="dv">10</span>, cmap<span class="op">=</span>plt.cm.Spectral)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 在三维空间构建最大间隔超平面</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> SVC(kernel<span class="op">=</span><span class="st">&#39;linear&#39;</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>clf.fit(X_3d, y)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 绘制三维决策平面</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>x1_min, x1_max <span class="op">=</span> X[:, <span class="dv">0</span>].<span class="bu">min</span>(), X[:, <span class="dv">0</span>].<span class="bu">max</span>()</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>x2_min, x2_max <span class="op">=</span> X[:, <span class="dv">1</span>].<span class="bu">min</span>(), X[:, <span class="dv">1</span>].<span class="bu">max</span>()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>x1, x2 <span class="op">=</span> np.mgrid[x1_min:x1_max:<span class="ot">200j</span>, x2_min:x2_max:<span class="ot">200j</span>]</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>x_grid <span class="op">=</span> np.stack((x1.ravel(), x2.ravel(), x1.ravel() <span class="op">**</span> <span class="dv">2</span> <span class="op">+</span> x2.ravel() <span class="op">**</span> <span class="dv">2</span>), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>y_hat <span class="op">=</span> clf.decision_function(x_grid)</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>y_grid <span class="op">=</span> y_hat.reshape((<span class="dv">200</span>, <span class="dv">200</span>))</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>ax.plot_surface(x1, x2, y_grid, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<p><a target="_blank" rel="noopener" href="https://imgse.com/i/pCHSwsH"><img
src="https://s1.ax1x.com/2023/07/20/pCHSwsH.png"
alt="pCHSwsH.png" /></a></p>
<p>SVM(支持向量机)的主要思想和实现方法可以概括如下:</p>
<ol type="1">
<li><p>思想:SVM试图找到一个最优分类超平面,使不同类样本
Reality隔的边界尽可能大,从而获得最佳的 GENERALIZATION能力。</p></li>
<li><p>实现:将样本映射到高维特征空间,转换为线性可分问题。在高维空间中求解最大间隔超平面作为决策面。</p></li>
<li><p>优化目标:构建约束优化问题,最小化||w||并满足分类约束。求解得到最优w和b确定超平面。</p></li>
<li><p>对偶问题:引入拉格朗日乘子α,将原问题转换为对偶问题,求解α即可得到最优超平面。</p></li>
<li><p>核技巧:通过核函数计算输入样本的内积,实现高维映射。常用核有线性核、多项式核、Gauss
RBF核等。</p></li>
<li><p>模型参数:主要就是支持向量及对应的α。决策函数只依赖支持向量。</p></li>
<li><p>实现方法:一般通过求解相应的凸二次规划问题获得最优α,然后求出w,b。常用SMO算法加速训练。</p></li>
<li><p>应用:可处理线性和非线性分类问题。还可以扩展到回归任务。</p></li>
</ol>
<p>SVM通过间隔最大化寻求最佳分类超平面,核技巧实现高维映射,是一种流行的分类与回归方法。</p>

</div>

        </div>
        
    </div>

    <!-- 引入 js 文件 -->
    
<script src="/js/main.js"></script>


    <!-- 引入代码高亮的 js -->
    
<script src="/lib/highlight/highlight.min.js"></script>

    <script>hljs.initHighlightingOnLoad();</script>

    <!-- 引入 jquery -->
    
<script src="/lib/jquery-3.5.1.min.js"></script>

    <script>hljs.initHighlightingOnLoad();</script>

    <!-- 引入 pjax -->
    
<script src="/lib/jquery.pjax.js"></script>



    <script src="https://blog-static.cnblogs.com/files/yyhh/L2Dwidget.min.js"></script>

    <script type="text/javascript">
    L2Dwidget.init();
</script>

</body>
</html>
                                                                                                     